{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brown.txt',\n",
       " 'cabs_ACP796_DISC_PLAN_VALIDATE_&@CC&@YY&@MM&@DD&@HH&@MM&@SS.dat',\n",
       " 'corrected_data.txt',\n",
       " 'Decommison Job List_INC1876529.txt',\n",
       " 'file gtp160.txt',\n",
       " 'gender_submission.csv',\n",
       " 'glove.6B',\n",
       " 'glove.6B.zip',\n",
       " 'glove.txt',\n",
       " 'gtp160 changes.txt',\n",
       " 'GTP160 NEXT.txt',\n",
       " 'kaggel word vec glove',\n",
       " 'logistic.txt',\n",
       " 'markv.py.txt',\n",
       " 'ner.txt',\n",
       " 'neural net.txt',\n",
       " 'neural network2.txt',\n",
       " 'new job.txt',\n",
       " 'new.txt',\n",
       " 'parts of speech tagging.txt',\n",
       " 'r8-test-all-terms.txt',\n",
       " 'r8-train-all-terms.txt',\n",
       " 'tensorflow.txt',\n",
       " 'test.csv',\n",
       " 'Test_bCtAN1w.csv',\n",
       " 'text classification code.txt',\n",
       " 'The effect of word embedding on bias.txt',\n",
       " 'tmmi MAIN POINTS.txt',\n",
       " 'toll optimization.txt',\n",
       " 'train.csv',\n",
       " 'train_modified.csv',\n",
       " 'train_modified1',\n",
       " 'Train_nyOWmfK.csv',\n",
       " 'tuning data.txt',\n",
       " 'validation file.txt',\n",
       " 'VBN.txt',\n",
       " 'Weekly Release Log 2019-08-08.xlsx',\n",
       " 'Weekly Release Log_Arcv 2019-08-15.xlsx',\n",
       " 'word2idx ten.txt',\n",
       " 'word2vec.txt',\n",
       " 'word_correct.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('C:\\\\Users\\\\ac36345\\\\Desktop\\\\nlp code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files_Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c8e32dc91a80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfiles_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mread_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_Path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp_array_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0memployee_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files_Path' is not defined"
     ]
    }
   ],
   "source": [
    "files_path = \"\"\n",
    "read_files = glob.glob(os.path.join(files_Path,\".csv\"))\n",
    "np_array_values = []\n",
    "for files in read_files:\n",
    "    employee_data = pd.read_csv(files,header=0)\n",
    "    np_array.values.append(employee_data)\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_array_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9525e5031948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerge_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_array_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0memployee_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#employee_data.columns = [\"ename\",\"job\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0memployee_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np_array_values' is not defined"
     ]
    }
   ],
   "source": [
    "merge_values = np.stack(np_array_values)\n",
    "employee_data = pd.DataFrame(merge_values)\n",
    "#employee_data.columns = [\"ename\",\"job\"]\n",
    "employee_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "newtestdata/mangodb.txt                        2019-10-09 15:29:26         2562\n",
      "newtestdata/Python code efficiency trick.txt   2019-10-11 00:28:58          238\n",
      "newtestdata/Python que.txt                     2019-10-10 15:12:00          325\n",
      "newtestdata/redata.txt                         2019-10-11 00:29:02          271\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# importing required modules \n",
    "from zipfile import ZipFile \n",
    "  \n",
    "# specifying the zip file name \n",
    "file_name = \"my_python_files.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "with ZipFile('C:\\\\Users\\\\ac36345\\\\Desktop\\\\newtestdata.zip', 'r') as zip: \n",
    "    # printing all the contents of the zip file \n",
    "    zip.printdir() \n",
    "  \n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zip.extractall() \n",
    "    print('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb,os\n",
    "\n",
    "path='testData'\n",
    "absPath = os.path.abspath(path)\n",
    "print absPath\n",
    "\n",
    "conn = MySQLdb.connect(host='localhost',\n",
    "                          user='root',\n",
    "                          passwd='',\n",
    "                          db='iens')\n",
    "\n",
    "db_cursor = conn.cursor()\n",
    "\n",
    "query = \"LOAD DATA INFILE '\"+ absPath + \"/rec.csv\" +\"' INTO TABLE iens.recensies FIELDS TERMINATED BY ' ' LINES TERMINATED BY '\\n' \"\n",
    "\n",
    "db_cursor.execute(query)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://usr:pass@localhost:5432/sqlalchemy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \n",
    "files = os.listdir(path)\n",
    "print(files)\n",
    "AllNames = pd.DataFrame()\n",
    "\n",
    "##if f[-5:] == '.xlsx'\n",
    "for f in files:\n",
    "    info = pd.read_excel(f,\"sheet1\")\n",
    "    AllNames = ALLNames.append(info)\n",
    "print(AllNames)\n",
    "\n",
    "\n",
    "#save result to excel\n",
    "writer = pd.excelWriter(\"nameoutput.xlsx\")\n",
    "AllNames.to_excel(writer,\"sheet1\")\n",
    "writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
